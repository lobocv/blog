[{"title":"Building a Comfortable Dev Environment","date":"","description":"","body":"Being a software developer can be overwhelming at times. There are an endlessly diverse set of tools, technologies, languages and frameworks to choose from. To make it worse, that list grows larger and larger each day. Tools like git, docker, docker-compose, kubernetes, ssh, curl, sed, awk, grep, jq etc. are all tools we use multiple times a day.\nMost of these tools have a small subset of commands / flags or use-cases that we use most often. In more complex cases, these tools can be piped together. As the years go by, with repetition, you end up memorizing these commands. This is great for productivity, but it takes time!\nIn the meantime, while you have yet to internalize these commands, your brain needs to stop (even for a second) to think: \u0026ldquo;What was that flag again?\u0026rdquo;\nThese small but frequent context switches cause us to lose a step on what is more important at the time: solving that bug, or finishing that feature. The solution is simple. Keep a cheatsheet of all your favorite commands written on cue cards. Tuck that cue card under your pillow and each night before bed, recite all the commands in their entirety out loud as you eventually fall asleep.\n\u0026hellip;\nNo. We\u0026rsquo;re not in school anymore (well some of you may be). There is a (much) better way of removing this unnecessary cognitive load so you can always stay focused on your task at hand.\nIn this article I am going to talk about a few things I do to speed up my development flow. I\u0026rsquo;ve found this incredibly valuable and I hope you do too. Best of all, you can take as much or as little from this flow as suites you.\nCustomize it, change it, improve it and share your results, I would love to hear it.\nLets get start with the simplest thing you can do:\nThe Shell Aliases A shell alias is a shortcut that you can define for any command. They are simple to create and can save you a lot of time and memorizing. For example, instead of typing ls -lah each time, you can create an alias la that would do the exact same thing:\nalias la=\u0026quot;ls -lAh\u0026quot; Aliases act as a run-time replacement of your alias with the defined command. This means you can augment your alias on the fly:\nla -R would translate to:\nls -lAh -R Aliases are a great way to turn that awkward to remember or type command into something dead simple that you can remember immediately. There is no alias too silly or simple. The following are probably my most commonly used aliases:\nalias cd.=\u0026quot;cd ..\u0026quot; alias cd..=\u0026quot;cd ../..\u0026quot; alias cd...=\u0026quot;cd ../../..\u0026quot; Lastly, aliases need to be loaded into your shell. The most common way of loading aliases is to define them in your .bashrc so that they are defined whenever you open a new shell.\nShell Functions An even more flexible option to aliases are shell functions. These act similarly to an alias but instead of simply replacing text being sent to your shell\u0026rsquo;s REPL, it executes the shell code you\u0026rsquo;ve defined. Use shell functions whenever you want to do something more complex than just shortcuts such as provide input arguments, flags and pipe input. Below is an example function to extract a specific JSON key-value from input:\n# Reads from JSON from stdin and print outs the value of the specified key # $1: Key to print # Example: echo '{\u0026quot;a\u0026quot;: 1, \u0026quot;b\u0026quot;: 2}' | jsonparsekey b # \u0026gt; 2 function jsonparsekey() { local KEY=$1 python -c \u0026quot;import sys,json; s=json.loads(''.join([l for l in sys.stdin])); print s['$KEY']\u0026quot; } I find this useful for filtering response data of HTTP APIs as I am debugging.\nCheck out some of my other aliases and shell functions.\nUpgrade from Bash Bash is ubiquitous and great, but over the years people have developed much more full-featured and customizable shells such as zsh and fish. I would highly recommend looking into these shells or the many others that exist. I personally use zsh with the oh-my-zsh configuration manager to extend and customize the shell to my liking.\nStoring your Configuration Over the years you will likely be using many different computers. I personally have my home desktop, a personal laptop and my work laptop. To keep configurations on all my devices in sync I have a git repository which stores all my aliases, shell functions, zsh plugins and common system packages. This repo also prevents me from losing and having to recreate configurations as I reinstall my OS or format my hard drives.\nI even have a script that loads the repository, keeping my .zshrc file edits minimal:\n.zshrc\nsource ~/lobocv/mysetup/load_aliases.sh Containerized Environments Docker and docker-compose make it simple to create a customized and reproducible development environment for your team\u0026rsquo;s software projects. In addition to the docker container, I have several scripts which help make common tasks dead simple. These tasks could be as trivial as building the docker image(s), starting and entering the development container and tearing it down when I\u0026rsquo;m finished.\nThe Docker Container At the heart of the development environment is the development container. This container contains all the tools and dependencies I would need in order to perform my daily tasks. If a public docker image with the main dependencies installed already exists, I use that as the base image for the dev container. For example, when I write Go applications, I use the golang docker image which already includes the go toolchain. Afterwards, I install any additional dependencies I need for the project such as protocol buffers and linters.\nDockerfile\nFROM golang:1.16 RUN go get google.golang.org/protobuf/cmd/protoc-gen-go \\  google.golang.org/grpc/cmd/protoc-gen-go-grpc Docker-compose makes it simple to orchestrate several containers which can then communicate with one another via a common network or share volumes with the host or one another. In the following docker-compose example config, I define the development container, dev, and mount my local filesystem (./) to a /src folder inside the container. This allows my development container have access to code in the repository and immediately see changes being made to them from my IDE.\nThe example configuration below also starts up a MongoDB container named mongo.\ndocker-compose.yaml\nversion: \u0026quot;3\u0026quot; services: dev: build: context: . dockerfile: ./Dockerfile command: sleep 1000000 volumes: - ./:/src mongo: image: mongo:4.4-bionic Accessing the Development Environment To make it fast and simple to get going, I write a bash script that starts the container(s) and enters the development container\u0026rsquo;s shell, which I call the devshell:\ndevshell.sh\n#!/usr/bin/env bash  PROJECT_NAME=myproject DEV_CONTAINER=dev RC_FILE=/src/.devshell_bashrc # If the -b flag is provided then build the containers before entering the shell if [ \u0026#34;$1\u0026#34; == \u0026#34;-b\u0026#34; ]; then docker-compose -p ${PROJECT_NAME} build fi # Check if the dev container is already up. If it\u0026#39;s not, then start it [ ! \u0026#34;$(docker ps | grep ${DEV_CONTAINER})\u0026#34; ] \u0026amp;\u0026amp; docker-compose -p ${PROJECT_NAME} up -d ${DEV_CONTAINER} # Enter the dev shell and load the rc file docker exec -it -e \u0026#34;TERM=xterm-256color\u0026#34; \u0026#34;${PROJECT_NAME}_${DEV_CONTAINER}_1\u0026#34; bash --rcfile ${RC_FILE} This script checks if the docker container is already running so that it does not always need to call the (somewhat) slow docker-compose up command.\nCustomizing the environment You may have noticed that in devshell.sh I provided an --rcfile parameter to bash. This allows us to setup any customized environment we want in the devshell. This can contain functions or aliases that are specific to your project. I like to have this script define a help() function and print it upon entry of the shell. This helps new team members joining the project get accustom to what features exist in the devshell. It also helps broadcast any improvements added to the shell and acts as reference documentation for the devshell.\n.devshell_bashrc\n# Define any common useful aliases or functions for the team  alias gotest=\u0026#34;go test ./...\u0026#34; alias testify=\u0026#34;go test -testify.m\u0026#34; alias lint=\u0026#34;golangci-lint run -v ./...\u0026#34; # Set default cd to go to project root alias cd=\u0026#39;HOME=/src cd\u0026#39; function help() { echo \u0026#34; ======================================= Welcome to the dev shell ======================================= Type \u0026#34;help\u0026#34; in the shell to repeat this message. Additional shell customizations can be loaded by creating a .customrc file in the root of the project. Here is a list of common commands you can do: * gotest: Run all go tests in the current directory * lint: Run golangci-lint in the current directory * testify: Run a testify test by name Arguments: 1 : Regex to match test names \u0026#34; } # Source any user-specific / personal aliases or functions if [[ -f .customrc ]]; then echo \u0026#34;Custom shell configuration found. Loading...\u0026#34; source .customrc fi help Personalizing the Shell At the end of the .devshell_bashrc script above, we source a .customrc file (if it exists). Each member of your team can use this file to personalize their devshell. Be sure to add .customrc to your project\u0026rsquo;s .gitignore so that someone does not accidentally share their own personal scripts.\nHere is an example of some additional personalization I do to my devshell:\n.customrc\n#!/bin/bash echo \u0026#34;Hi Calvin!\u0026#34; alias cd.=\u0026#34;cd ..\u0026#34; alias cd..=\u0026#34;cd ../..\u0026#34; alias cd...=\u0026#34;cd ../../..\u0026#34; alias la=\u0026#34;ls -lah\u0026#34; alias gofmt=\u0026#34;gofmt -w -s .\u0026#34; alias run=\u0026#39;go run ./...\u0026#39; While these examples are pretty general purpose, there are many ways you can tailor your environment to speed up your development flows. Be creative! Here are some ideas:\n Changing to a particular directory which I often use Run a particular tool such as generating proto files Building and running a program / service via a regex Changing to a particular project directory via a regex Shortcuts interacting with ElasticSearch: List/delete aliases, templates, indices  Teardown and Cleanup Tearing down the containers is as simple as calling docker-compose down. Although this is a simple command, having it defined as a script opens the door to add more functionality such as only shutting down certain containers. It also provides nice symmetry to devshell.sh and makes things dead simple.\ndevdown.sh\n#!/usr/bin/env bash  PROJECT_NAME=myproject docker-compose -p ${PROJECT_NAME} down --remove-orphans Try it yourself A working example of this development environment can be found at my project-bootstrap repository. Feel free to try it out!\nMake it your own There is a lot of focus on optimizing your code or algorithms, but optimizing your development efficiency is one of the highest impact changes you can make. These are just some examples of what you can do. Be creative and come up with your own optimizations. Keep track of the context changes and inefficiencies in your workflow and you\u0026rsquo;ll bee surprised how much of an impact it can have on your output. Keep in mind, that unlike code, these gains with follow you throughout your professional career.\n","ref":"/posts/dev_environment/"},{"title":"Recursively Merging JSONB in PostgreSQL","date":"","description":"","body":"In addition to storing primitive data types such as INT, FLOAT and VARCHAR, PostgreSQL supports storing JSON and binary JSON (JSONB). These JSON types have a wide variety of functions and operators[1]. One of the more common and useful operators is the concatenation operator, ||, which concatenates two jsonb values into a new JSONB value.\nExample:\npostgres=\u0026gt; SELECT \u0026#39;{\u0026#34;a\u0026#34;: 1, \u0026#34;b\u0026#34;: 2}\u0026#39;::jsonb || \u0026#39;{\u0026#34;b\u0026#34;: 5, \u0026#34;c\u0026#34;: 6}\u0026#39;::jsonb as result; result -------------------------- {\u0026#34;a\u0026#34;: 1, \u0026#34;b\u0026#34;: 5, \u0026#34;c\u0026#34;: 6} However, this concatenation is limiting. For one, if a key is present in both arguments, the second value will completely overwrite the first. This is a problem for nested objects. The following example attempts to update the \u0026quot;author.age\u0026quot; value from 30 to 31, but also ends up removing the author.name field.\nSELECT \u0026#39;{\u0026#34;author\u0026#34;: {\u0026#34;age\u0026#34;: 30, \u0026#34;name\u0026#34;: \u0026#34;Calvin\u0026#34;}}\u0026#39;::jsonb || \u0026#39;{\u0026#34;author\u0026#34;: {\u0026#34;age\u0026#34;: 31}}\u0026#39;::jsonb as result; result -------------------- {\u0026#34;author\u0026#34;: {\u0026#34;age\u0026#34;: 31}} In order to preserve objects and have their fields merged instead of overwritten, we need to write a custom function.\nHere is the full function which recursively merges two JSON objects A  and B:\nCREATE OR REPLACE FUNCTION jsonb_recursive_merge(A jsonb, B jsonb) RETURNS jsonb LANGUAGE SQL AS $$ SELECT jsonb_object_agg( coalesce(ka, kb), CASE WHEN va isnull THEN vb WHEN vb isnull THEN va WHEN jsonb_typeof(va) \u0026lt;\u0026gt; \u0026#39;object\u0026#39; OR jsonb_typeof(vb) \u0026lt;\u0026gt; \u0026#39;object\u0026#39; THEN vb ELSE jsonb_recursive_merge(va, vb) END ) FROM jsonb_each(A) temptable1(ka, va) FULL JOIN jsonb_each(B) temptable2(kb, vb) ON ka = kb $$; This function may be a bit hard to digest, so let\u0026rsquo;s break it down:\nSELECT jsonb_object_agg( ... ) FROM jsonb_each(A) temptableA(ka, va) FULL JOIN jsonb_each(B) temptableB(kb, vb) ON ka = kb jsonb_object_agg is a built-in postgresql function which aggregates a list of (key, value) pairs into a JSON object. This is what creates the final merged JSON result. Here we are applying jsonb_object_agg on the results of an in-memory temporary table that we are creating on the fly.\nTemporary tables jsonb_each() is a built-in postgresql function that iterates a JSON object returning (key, value) pairs. We call this function on both input JSON object A and B and then store the results in temporary tables temptableA and temptableB respectively.\ntemptableA(ka, va) is the definition of a temporary table with columns ka and va for the key and value results of jsonb_each(). This is where ka and va are first introduced. We do the exact same thing for JSON object B to get kb and vb.\nNext we do a FULL JOIN with the two temporary tables on the key column. This gives us one table that has all the (key, value) pairs from both JSON objects A and B. Below is an example of what the results of that table may look like:\n   ka va kb vb     likes 5 likes 10     comments 3   shares 1     impressions 65 impressions 130    Table 1: An example of a FULL JOIN with two temporary tables produced by jsonb_each()\nIt is this table from which we select the input to jsonb_object_agg(). As we iterate through the rows of this joined temporary table, we need to determine which key (ka or kb) and value (va or vb) we want to place in the resultant JSON object.\nSelecting the Key coalesce(ka, kb) coalesce is a built in postgresql function that returns the first non null value it is given. In this case it will choose ka if kb is null or kb if ka is null. Since we performed our FULL JOIN on columns ka = kb, we are guaranteed to have a non-null value for either ka or kb. When both ka and kb are non-null, they will be the same value.\nSelecting the Value CASE WHEN va isnull THEN vb WHEN vb isnull THEN va WHEN jsonb_typeof(va) \u0026lt;\u0026gt; \u0026#39;object\u0026#39; OR jsonb_typeof(vb) \u0026lt;\u0026gt; \u0026#39;object\u0026#39; THEN vb ELSE jsonb_recursive_merge(va, vb) END To select the value, we have a switch statement. The first two cases chooses the non-null value when one of the values is null. The third case is when both va and vb are defined and not both JSON objects themselves. In this case we choose vb over va (remember we are merging B into A). The final case (else) handles the situation where va and vb are both JSON objects. In that situation we recursively call the jsonb_recursive_merge on va and vb.\nUsing the function One common use for this function is to upsert a row. In an upsert, when the row exists, you want to update it and when it doesn\u0026rsquo;t, you want to insert a new one. To do this, you would use an INSERT statement with the ON CONFLICT (col1,..., colN) DO UPDATE SET clause. The columns in the clause specify the columns of a unique index. Following the clause is a list of column_name = \u0026lt;expression\u0026gt; statements that decide just how each column is to be updated.\nBelow is an example of updating a table of tweet metrics:\nINSERT INTO tweets (id, metrics) VALUES (1, \u0026#39;{\u0026#34;likes\u0026#34;: 22, \u0026#34;comments\u0026#34;: 12}\u0026#39;) ON CONFLICT (id) DO UPDATE SET metrics = jsonb_recursive_merge(tweets.metrics, excluded.metrics); In the statement above, if a row with the same ID exists, it will call the jsonb_recursive_merge function on the current value, tweets.metrics, and the inserted value, excluded.metrics (the excluded table is the name of the special table representing rows proposed for insertion[2]).\nLimitations When we designed our jsonb_recursive_merge function we had to decide what \u0026ldquo;merge\u0026rdquo; meant to us. We decided that an overwrite of a value constitutes a \u0026ldquo;merge\u0026rdquo;. But what about values that are arrays? One could argue that merging two arrays [1, 2, 3] and [4, 5, 6] should result in [1,2,3,4,5,6]. It really all depends on the context of what you are trying to do.\nIf you want to also merge the values of arrays you can add an extra case statement that appends the values when both va and vb are arrays:\nWHEN jsonb_typeof(va) = \u0026#39;array\u0026#39; AND jsonb_typeof(vb) = \u0026#39;array\u0026#39; THEN va || vb However, be aware that this will apply to all arrays encountered in the JSON objects.\nAnd there you have it, a custom PostgreSQL function that merges two JSON objects, preserving and merging any nested objects. I\u0026rsquo;d like to thank and give credit to klin and his very helpful StackOverflow answer which brought me to a solution to this problem.\nFurther Reading [1] JSON Functions and Operators\n[2] PostgresSQL Insert Documentation\n","ref":"/posts/recursive_jsonb_merge/"},{"title":"About","date":"","description":"","body":"I am a backend software developer that has a passion for software architecture, scalability, development efficiency and clean code. I love learning and sharing what I have learned with others.\nAside from work, I love to play electric guitar, renovate my home and be out in nature.\n","ref":"/about/"}]